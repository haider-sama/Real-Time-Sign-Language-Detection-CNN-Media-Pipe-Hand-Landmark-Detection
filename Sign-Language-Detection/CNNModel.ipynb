{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05263c9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from torch.nn import (\n",
    "    Linear, ReLU, Sequential, Conv1d, MaxPool1d, Module, BatchNorm1d, Dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c95127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.cnnLayers = Sequential(\n",
    "            # First convolutional block\n",
    "            Conv1d(in_channels=63, out_channels=32, kernel_size=3, stride=1, padding=2),\n",
    "            BatchNorm1d(32),\n",
    "            ReLU(),\n",
    "\n",
    "            # Second convolutional block\n",
    "            Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=2),\n",
    "            BatchNorm1d(64),\n",
    "            ReLU(),\n",
    "            MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Third convolutional block\n",
    "            Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=2),\n",
    "            BatchNorm1d(128),\n",
    "            ReLU(),\n",
    "            Dropout(p=0.3),\n",
    "\n",
    "            # Fourth convolutional block\n",
    "            Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=2),\n",
    "            BatchNorm1d(256),\n",
    "            ReLU(),\n",
    "            MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Fifth convolutional block\n",
    "            Conv1d(in_channels=256, out_channels=512, kernel_size=5, stride=1, padding=2),\n",
    "            BatchNorm1d(512),\n",
    "            ReLU(),\n",
    "            MaxPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Sixth convolutional block\n",
    "            Conv1d(in_channels=512, out_channels=512, kernel_size=5, stride=1, padding=2),\n",
    "            BatchNorm1d(512),\n",
    "            ReLU(),\n",
    "            Dropout(p=0.3),\n",
    "        )\n",
    "\n",
    "        # Linear layers\n",
    "        self.linearLayers = Sequential(\n",
    "            Linear(in_features=512, out_features=26),\n",
    "            BatchNorm1d(26),\n",
    "            ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        # Pass input through convolutional layers\n",
    "        x = self.cnnLayers(x)\n",
    "\n",
    "        # Flatten the tensor for the linear layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Pass flattened tensor through linear layers\n",
    "        x = self.linearLayers(x)\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
