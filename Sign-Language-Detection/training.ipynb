{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcae476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from CNN.CNNModel import CNNModel\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cc04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to move data to CUDA if available\n",
    "def to_cuda(tensor):\n",
    "    return tensor.cuda() if torch.cuda.is_available() else tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef910fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    if y_true.dim() > 1 and y_true.size(1) > 1:\n",
    "        y_true = torch.argmax(y_true, dim=1)\n",
    "\n",
    "    predicted_classes = torch.argmax(y_pred, dim=1)\n",
    "    correct_predictions = (predicted_classes == y_true).float()\n",
    "    return correct_predictions.sum() / len(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5690e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot accuracy graph\n",
    "def plot_accuracy_graph(train_accuracies, val_accuracies, epochs):\n",
    "    plt.plot(range(1, epochs + 1), train_accuracies, 'bo-', label='Training Accuracy')\n",
    "    plt.plot(range(1, epochs + 1), val_accuracies, 'ro-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db295297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot loss graph\n",
    "def plot_loss_graph(train_losses, val_losses):\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_excel(\"../featureExtraction/alphabet_data.xlsx\", header=0)\n",
    "data.pop(\"CHARACTER\")\n",
    "group_value, coordinates = data.pop(\"GROUPVALUE\"), data.copy()\n",
    "coordinates = np.reshape(coordinates.values, (coordinates.shape[0], 63, 1))\n",
    "coordinates = torch.from_numpy(coordinates).float()\n",
    "group_value = torch.from_numpy(group_value.to_numpy()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9976ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 4\n",
    "epochs = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f152074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to store fold-wise results\n",
    "fold_train_losses, fold_val_losses = [], []\n",
    "fold_train_accuracies, fold_val_accuracies = [], []\n",
    "fold_train_precision, fold_val_precision = [], []\n",
    "fold_train_recall, fold_val_recall = [], []\n",
    "fold_train_f1, fold_val_f1 = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39260d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18413130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(coordinates)):\n",
    "    print(f\"Training on fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Split data for the current fold\n",
    "    training, group_value_training = coordinates[train_idx], group_value[train_idx]\n",
    "    validation, group_value_validation = coordinates[val_idx], group_value[val_idx]\n",
    "\n",
    "    # Model and optimizer setup\n",
    "    model = CNNModel()\n",
    "    model = to_cuda(model)\n",
    "    optimizer = Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Initialize lists for losses, accuracies, and metrics\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    train_precisions, train_recalls, train_f1s = [], [], []\n",
    "    val_precisions, val_recalls, val_f1s = [], [], []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move data to CUDA\n",
    "        training, validation = to_cuda(training), to_cuda(validation)\n",
    "        group_value_training, group_value_validation = to_cuda(group_value_training), to_cuda(group_value_validation)\n",
    "\n",
    "        # Forward pass\n",
    "        output_train = model(training)\n",
    "        output_val = model(validation)\n",
    "\n",
    "        # Compute loss\n",
    "        loss_train = criterion(output_train, group_value_training)\n",
    "        train_losses.append(loss_train.item())\n",
    "        loss_val = criterion(output_val, group_value_validation)\n",
    "        val_losses.append(loss_val.item())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Switch to evaluation mode for accuracy calculation\n",
    "        with torch.no_grad():\n",
    "            train_output = model(training).cpu()\n",
    "            train_accuracy = calculate_accuracy(group_value_training, train_output)\n",
    "            train_accuracies.append(train_accuracy.item())\n",
    "\n",
    "            output_valid = model(validation).cpu()\n",
    "            val_accuracy = calculate_accuracy(group_value_validation, output_valid)\n",
    "            val_accuracies.append(val_accuracy.item())\n",
    "\n",
    "        # Calculate metrics\n",
    "        train_prec = precision_score(group_value_training.cpu(), torch.argmax(train_output, dim=1), average='weighted', zero_division=0)\n",
    "        train_rec = recall_score(group_value_training.cpu(), torch.argmax(train_output, dim=1), average='weighted', zero_division=0)\n",
    "        train_f1 = f1_score(group_value_training.cpu(), torch.argmax(train_output, dim=1), average='weighted', zero_division=0)\n",
    "\n",
    "        val_prec = precision_score(group_value_validation.cpu(), torch.argmax(output_valid, dim=1), average='weighted', zero_division=0)\n",
    "        val_rec = recall_score(group_value_validation.cpu(), torch.argmax(output_valid, dim=1), average='weighted', zero_division=0)\n",
    "        val_f1 = f1_score(group_value_validation.cpu(), torch.argmax(output_valid, dim=1), average='weighted', zero_division=0)\n",
    "\n",
    "        # Store metrics\n",
    "        train_precisions.append(train_prec)\n",
    "        train_recalls.append(train_rec)\n",
    "        train_f1s.append(train_f1)\n",
    "        val_precisions.append(val_prec)\n",
    "        val_recalls.append(val_rec)\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        # Print progress every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Fold {fold + 1}, Epoch {epoch}, Train Loss: {loss_train.item()}, Val Loss: {loss_val.item()}')\n",
    "\n",
    "    # Store fold-wise results\n",
    "    fold_train_losses.append(train_losses)\n",
    "    fold_val_losses.append(val_losses)\n",
    "    fold_train_accuracies.append(train_accuracies)\n",
    "    fold_val_accuracies.append(val_accuracies)\n",
    "    fold_train_precision.append(train_precisions)\n",
    "    fold_train_recall.append(train_recalls)\n",
    "    fold_train_f1.append(train_f1s)\n",
    "    fold_val_precision.append(val_precisions)\n",
    "    fold_val_recall.append(val_recalls)\n",
    "    fold_val_f1.append(val_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53743f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average results across folds\n",
    "avg_train_loss = np.mean(fold_train_losses, axis=0)\n",
    "avg_val_loss = np.mean(fold_val_losses, axis=0)\n",
    "avg_train_accuracy = np.mean(fold_train_accuracies, axis=0)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies, axis=0)\n",
    "avg_train_prec = np.mean(fold_train_precision, axis=0)\n",
    "avg_train_rec = np.mean(fold_train_recall, axis=0)\n",
    "avg_train_f1 = np.mean(fold_train_f1, axis=0)\n",
    "avg_val_prec = np.mean(fold_val_precision, axis=0)\n",
    "avg_val_rec = np.mean(fold_val_recall, axis=0)\n",
    "avg_val_f1 = np.mean(fold_val_f1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63465556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_loss_graph(avg_train_loss, avg_val_loss)\n",
    "plot_accuracy_graph(avg_train_accuracy, avg_val_accuracy, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1010fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final average performance\n",
    "print(f\"Final Average Training Accuracy: {avg_train_accuracy[-1] * 100:.2f}%\")\n",
    "print(f\"Final Average Validation Accuracy: {avg_val_accuracy[-1] * 100:.2f}%\")\n",
    "print(f\"Final Average Training Precision: {avg_train_prec[-1] * 100:.2f}%\")\n",
    "print(f\"Final Average Validation Precision: {avg_val_prec[-1] * 100:.2f}%\")\n",
    "print(f\"Final Average Training Recall: {avg_train_rec[-1] * 100:.2f}%\")\n",
    "print(f\"Final Average Validation Recall: {avg_val_rec[-1] * 100:.2f}%\")\n",
    "print(f\"Final Average Training F1-Score: {avg_train_f1[-1] * 100:.2f}%\")\n",
    "print(f\"Final Average Validation F1-Score: {avg_val_f1[-1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"CNN_model_alphabet_SIBI.pth\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
